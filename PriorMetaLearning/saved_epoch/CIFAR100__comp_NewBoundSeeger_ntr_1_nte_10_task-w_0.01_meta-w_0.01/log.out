Log file created at  2019-05-16 18:37:16
Run script: main_Meta_Bayes.py
Parameters:
Namespace(K_Shot_MetaTest=50, K_Shot_MetaTrain=50, N_Way=5, batch_size=16, chars_split_type='random', complexity_type='NewBoundSeeger', data_path='/data5/tlgao/meta/meta-learning-adjusting-priors/ML_data_sets', data_source='CIFAR100', data_transform='None', from_pretrain=None, limit_train_samples_in_test_tasks=2000, load_model_path='', loss_type='CrossEntropy', lr=0.001, meta_batch_size=16, meta_complex_w=0.01, mode='LoadMetaModel', model_name='CIFARNet', n_inner_steps=50, n_meta_test_epochs=40, n_meta_train_chars=1200, n_meta_train_classes=500, n_meta_train_epochs=50, n_pixels_shuffles=200, n_test_tasks=10, n_train_tasks=1, result_dir='saved_epoch/CIFAR100__comp_NewBoundSeeger_ntr_1_nte_10_task-w_0.01_meta-w_0.01', run_name='CIFAR100__comp_NewBoundSeeger_ntr_1_nte_10_task-w_0.01_meta-w_0.01', seed=1, task_complex_w=0.01, test_batch_size=128)
--------------------------------------------------
Pre-trained  prior loaded from saved_epoch/CIFAR100__comp_NewBoundSeeger_ntr_1_nte_10_task-w_0.01_meta-w_0.01/model.pt
---- Generating 10 test-tasks with at most 2000 training samples
Meta-Testing with transferred prior....
---------------------Test on Epoch_10------------------------
Meta-Testing task 1 out of 10...
(0.0%)	Epoch: 0 	 Batch: 0 	 Objective: 1.617 	  Acc: 0.188	 Empiric Loss: 1.614	 Intra-Comp. 0.3401, w_kld 0.0, b_kld 0.0
(2.5%)	Epoch: 1 	 Batch: 0 	 Objective: 1.178 	  Acc: 0.562	 Empiric Loss: 1.175	 Intra-Comp. 0.2978, w_kld 0.0001127, b_kld 4.293e-05
(5.0%)	Epoch: 2 	 Batch: 0 	 Objective: 1.418 	  Acc: 0.438	 Empiric Loss: 1.415	 Intra-Comp. 0.3218, w_kld 0.0002295, b_kld 0.0001276
(7.5%)	Epoch: 3 	 Batch: 0 	 Objective: 1.088 	  Acc: 0.5	 Empiric Loss: 1.086	 Intra-Comp. 0.2883, w_kld 0.0003082, b_kld 0.0002738
(10.0%)	Epoch: 4 	 Batch: 0 	 Objective: 0.7252 	  Acc: 0.875	 Empiric Loss: 0.7227	 Intra-Comp. 0.2447, w_kld 0.0003931, b_kld 0.0004197
(12.5%)	Epoch: 5 	 Batch: 0 	 Objective: 0.9306 	  Acc: 0.562	 Empiric Loss: 0.9279	 Intra-Comp. 0.2704, w_kld 0.000479, b_kld 0.0005704
(15.0%)	Epoch: 6 	 Batch: 0 	 Objective: 0.5606 	  Acc: 0.875	 Empiric Loss: 0.5584	 Intra-Comp. 0.2214, w_kld 0.0005664, b_kld 0.000733
(17.5%)	Epoch: 7 	 Batch: 0 	 Objective: 0.7959 	  Acc: 0.625	 Empiric Loss: 0.7934	 Intra-Comp. 0.254, w_kld 0.0006492, b_kld 0.0008769
(20.0%)	Epoch: 8 	 Batch: 0 	 Objective: 0.5564 	  Acc: 0.875	 Empiric Loss: 0.5542	 Intra-Comp. 0.2207, w_kld 0.0007601, b_kld 0.001056
(22.5%)	Epoch: 9 	 Batch: 0 	 Objective: 0.6465 	  Acc: 0.812	 Empiric Loss: 0.6441	 Intra-Comp. 0.2339, w_kld 0.0008875, b_kld 0.001257
(25.0%)	Epoch: 10 	 Batch: 0 	 Objective: 0.4233 	  Acc: 0.812	 Empiric Loss: 0.4213	 Intra-Comp. 0.1991, w_kld 0.001021, b_kld 0.001396
(27.5%)	Epoch: 11 	 Batch: 0 	 Objective: 0.3298 	  Acc: 0.938	 Empiric Loss: 0.328	 Intra-Comp. 0.1817, w_kld 0.001142, b_kld 0.001594
(30.0%)	Epoch: 12 	 Batch: 0 	 Objective: 0.1965 	  Acc: 1.0	 Empiric Loss: 0.1949	 Intra-Comp. 0.1519, w_kld 0.001274, b_kld 0.001668
(32.5%)	Epoch: 13 	 Batch: 0 	 Objective: 0.2665 	  Acc: 1.0	 Empiric Loss: 0.2648	 Intra-Comp. 0.1685, w_kld 0.001419, b_kld 0.001814
(35.0%)	Epoch: 14 	 Batch: 0 	 Objective: 0.2486 	  Acc: 0.938	 Empiric Loss: 0.2469	 Intra-Comp. 0.1645, w_kld 0.001567, b_kld 0.001883
(37.5%)	Epoch: 15 	 Batch: 0 	 Objective: 0.165 	  Acc: 0.938	 Empiric Loss: 0.1635	 Intra-Comp. 0.1435, w_kld 0.001689, b_kld 0.002002
